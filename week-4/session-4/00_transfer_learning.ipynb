{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byrocuy/REA_AI_Bootcamp/blob/main/week-4/session-4/00_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSpJl32SNBBY"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "![](https://storage.googleapis.com/rg-ai-bootcamp/model_usage/transfer-learning.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDhopevVNBBd"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Struggling to train complex models due to limited high-quality data and resources? ðŸ¤” Don't panic! The answer is **Transfer Learning**. This technique leverages pre-trained models, like BERT for NLP or [ImageNet](https://www.image-net.org/) for image classification, to significantly cut down training time. Think of it as teaching an old dog new tricks: you can easily adapt, say an ImageNet model, to tasks like dog breed classification. And voila! You've just made quick progress even with scarce data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGSugT3SNBBf"
      },
      "source": [
        "## How does Neural Network change in Transfer Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FElxVvtCNBBf"
      },
      "source": [
        "Imagine a chef who is skilled in baking cakes. Now, suppose this chef needs to cook a new dish, like pasta. Instead of starting from scratch, they leverage their existing culinary skills, adjusting only where necessary for the pasta-specific nuances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXy5ue9VNBBg"
      },
      "source": [
        "Similarly, in machine learning, two possible approaches exist: \"Training from Scratch\" and \"Transfer Learning\". In the former, a model like CNN is trained on a new dataset, say Vehicles, without any prior knowledge. In the latter, the model leverages prior knowledge acquired from a different dataset, like Animals, and adjusts this understanding to the new task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLyKTbqfNBBg"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:720/0*xNjEPIZmPvKeqss6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHazIMuUNBBh"
      },
      "source": [
        "The image above illustrates this concept. As shown, a model trained from scratch (the top one) is set up to learn directly from the Vehicles dataset. It starts with no inherent understanding of images and must learn the features that differentiate one vehicle from another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIIutz52NBBh"
      },
      "source": [
        "In contrast, a model using transfer learning (the bottom one) begins with a pre-trained network that has pre-existing knowledge about different animals. This model is fine-tuned to distinguish different types of vehicles, typically achieving faster and more efficient results than training from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgiEZfP6NBBk"
      },
      "source": [
        "In essence, while both models aim to classify different types of vehicles, they learn differently: the model trained from scratch learns all features independently, like a chef learning a new dish from scratch, whereas the transfer learning model refines existing knowledge for the new task, similar to a chef adapting their existing skills to a new recipe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G8xJ0zxNBBk"
      },
      "source": [
        "## Fine-Tuning a Model\n",
        "\n",
        "In the context of transfer learning, fine-tuning a pre-trained model to a specific task is an efficient way to leverage existing knowledge and adapt it to novel use cases. To effectively carry out this process, the key steps are:\n",
        "- **Load Dataset**: Prepare and load the new data.\n",
        "- **Preprocess**: Tokenize and format the data to match the model's input.\n",
        "- **Setting up Evaluation Metric**: Define the 'accuracy' metric to evaluate the model's performance.\n",
        "- **Training and Evaluation**: Train and optimize the model through epochs, evaluating the model after each epoch.\n",
        "- **Evaluating the Trained Model**: Test the model's performance on a separate test dataset.\n",
        "- **Inference**: Use the trained model for predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v69UMnm3NBBl"
      },
      "source": [
        "## Use Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUwMWo71NBBm"
      },
      "source": [
        "Transfer learning has been widely applied for diverse applications. Some of these applications include:\n",
        "\n",
        "1. **Natural Languange Processing (NLP)**\n",
        "   - Text Classification\n",
        "   - Summarization\n",
        "   - And more\n",
        "2. **Audio**\n",
        "   - Audio classification\n",
        "   - Automatic speech recognition\n",
        "   - And more\n",
        "3. **Computer Vision**\n",
        "   - Image Classification\n",
        "   - Object detection\n",
        "   - And more\n",
        "4. **Multimodal**\n",
        "   - Image Captioning\n",
        "   - Document Question Answering\n",
        "   - And more\n",
        "\n",
        "By utilizing transfer learning, we can significantly improve the performance of these tasks and many more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWsqJxybNBBm"
      },
      "source": [
        "### Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogZUmiiHNBBm"
      },
      "source": [
        "[![](https://storage.googleapis.com/rg-ai-bootcamp/model_usage/text-classification.png)](https://youtu.be/leNG9fN9FQU)\n",
        "\n",
        "Tasks: Text Classification (source: [youtube.com](https://youtu.be/leNG9fN9FQU))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn4zq8ysNBBn"
      },
      "source": [
        "Transfer learning for text classification comes to the rescue when we aim to discern the sentiment of movie reviews. The state-of-the-art models like [DistilBERT](https://huggingface.co/distilbert-base-uncased), which are already trained on a diverse range of internet text, can provide us a robust feature-extraction foundation. We retrain this model on the [IMDb](https://huggingface.co/datasets/imdb) dataset to classify whether a movie review carries a positive or negative sentiment. This pre-trained model significantly cuts down our training time and needs less data than starting from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfM5_gqGNBBo"
      },
      "source": [
        "Before you begin, make sure you have all the necessary libraries installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7A4luAiNBBo"
      },
      "outputs": [],
      "source": [
        "%pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPdYMp9pNBBq"
      },
      "source": [
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRKWTexgNBBq"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQlPmVP7NBBt"
      },
      "source": [
        "**Load IMDb dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF01Y01HNBBt"
      },
      "source": [
        "Start by loading the IMDb dataset from the Datasets library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_EE7gxFNBBu"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbX7a0fNNBBv"
      },
      "source": [
        "Then take a look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19efsJKMNBBv"
      },
      "outputs": [],
      "source": [
        "imdb[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPbqKIA6NBBw"
      },
      "source": [
        "There are two fields in this dataset:\n",
        "\n",
        "- `text`: the movie review text.\n",
        "- `label`: a value that is either 0 for a negative review or 1 for a positive review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihKbJpHtNBBw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Select a part of the dataset (e.g. 'train', 'test', or 'unsupervised', depending on what part you want to see)\n",
        "imdb_set = imdb['train']\n",
        "df = pd.DataFrame(imdb_set)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MGEVxkqNBBx"
      },
      "source": [
        "**Preprocess**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxXCo-9oNBBx"
      },
      "source": [
        "The next step is to load a `DistilBERT` tokenizer to preprocess the text field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q03iWHbzNBBy"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkX_dBtMNBBy"
      },
      "source": [
        "Create a preprocessing function to tokenize text and truncate sequences to be no longer than `DistilBERTâ€™s` maximum input length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9FBdFbTNBBz"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37N5IaW_NBB0"
      },
      "source": [
        "Use the Datasets map function to apply the preprocessing function over the full dataset. Quicken the process by setting `batched=True` for simultaneous processing of multiple dataset elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TO-iVenNBB0"
      },
      "outputs": [],
      "source": [
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTePgc2cNBB1"
      },
      "source": [
        "Use `DataCollatorWithPadding` to create a batch of examples. It's more efficient to pad sentences to the max length in a batch during collation, rather than padding the entire dataset to the max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoNA5D4rNBB1"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGlvZAHlNBB2"
      },
      "source": [
        "**Setting up Evaluation Metric**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKjKkzyqNBB2"
      },
      "source": [
        "We use 'accuracy' as the evaluation metric because it is a simple yet effective metric for classification tasks, and is especially useful when the classes are balanced, as in the case of the IMDb dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBfN77OSNBB3"
      },
      "outputs": [],
      "source": [
        "%pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4nOw5H2NBB3"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dthISCPqNBB8"
      },
      "source": [
        "Then create a function that passes your predictions and labels to compute to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4xj_znvNBB9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtVXxHjbNBB9"
      },
      "source": [
        "Your compute_metrics function is ready to go now, and youâ€™ll return to it when you setup your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V93cIi5JNBB9"
      },
      "source": [
        "**Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqNonwc_NBB9"
      },
      "source": [
        "The process of training involves both optimizing the parameters of the model and evaluating its performance. After each epoch of training, the model is evaluated on the validation data. The evaluation metric used is accuracy which we've defined in the previous section. Based on this evaluation, the training process may decide to continue training the model, to halt and save it, or even to revert to a previous state of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxSp66AdNBB-"
      },
      "source": [
        "Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv3sK_mXNBB-"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ3YkxBbNBB-"
      },
      "source": [
        "Youâ€™re ready to start training your model now! Load DistilBERT with [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/auto#transformers.AutoModelForSequenceClassification) along with the number of expected labels, and the label mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHBdiYaUNBB-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGd8zjN-NBB-"
      },
      "source": [
        "After load the model, it's now time to set your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/trainer#transformers.TrainingArguments), specifying `output_dir` and enabling `push_to_hub` to upload your model to Hugging Face."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6b88FK-NBB_"
      },
      "source": [
        "One critical argument here is `load_best_model_at_end=True`, which ensures that the trainer will load the best model (with respect to the evaluation metric) at the end of training. This way, we'll always end up with the model that performed best on the validation set during the training phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwGaSvNPNBB_"
      },
      "source": [
        "To use Hugging Face `Trainer` you need to install the accelerate library version `0.20.1` or later. It is used for performance enhancement on PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGWOYhdqNBB_"
      },
      "outputs": [],
      "source": [
        "%pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmY0v4f4NBB_"
      },
      "source": [
        "To speed up the training process, you could try **Use a GPU if available**: If you're running your code on Google Colab, you can adjust the settings to utilize a GPU. Click on `Runtime -> Change runtime type -> Hardware accelerator -> Choose GPU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUlBcQxXNBB_"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"model/text_classification\",\n",
        "    learning_rate=2e-5,                            # learning rate\n",
        "    per_device_train_batch_size=16,                # training batch size\n",
        "    per_device_eval_batch_size=16,                 # evaluation batch size\n",
        "    num_train_epochs=2,                            # number of training epochs\n",
        "    weight_decay=0.01,                             # weight decay for regularization\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,                   # early stopping\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"],\n",
        "    eval_dataset=tokenized_imdb[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XLhQrVZNBCA"
      },
      "source": [
        "**Evaluating the Trained Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hiteny-4NBCA"
      },
      "source": [
        "After training, it's time to evaluate the model on a separate test dataset. This can give us a good understanding of how well the model performs on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY4cZh6lNBCA"
      },
      "outputs": [],
      "source": [
        "eval_result = trainer.evaluate(eval_dataset=tokenized_imdb[\"test\"])\n",
        "print(eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjV8n5ltNBCA"
      },
      "source": [
        "The evaluation results will give us the accuracy on the test set. If this accuracy is satisfactory, we could then decide to publish the model. If it's not, we might need to revisit the preprocessing, model architecture, or the training process (e.g., tuning hyperparameters, increasing number of epochs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzX4i-KqNBCA"
      },
      "source": [
        "Once training is completed, share your model to the Hub with the `push_to_hub()` method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z30S_OjkNBCA"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfVrfxlyNBCB"
      },
      "source": [
        "The following is an example of a model that has been trained: <https://huggingface.co/aditira/text_classification>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMbOo43wNBCB"
      },
      "source": [
        "**Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRdxgsVBNBCB"
      },
      "source": [
        "Great, now that youâ€™ve finetuned a model, you can use it for inference! Grab some text youâ€™d like to run inference on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O40YE29DNBCB"
      },
      "outputs": [],
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEHGI3RJNBCB"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a pipeline(). Instantiate a pipeline for sentiment analysis with your model, and pass your text to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5_i-gCtNBCC"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"model/text_classification\")\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPW9OAFNBCC"
      },
      "source": [
        "### Audio Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dghRP8vJNBCC"
      },
      "source": [
        "[![](https://storage.googleapis.com/rg-ai-bootcamp/model_usage/audio-classification.png)](https://youtu.be/KWwzcmG98Ds)\n",
        "\n",
        "Tasks: Audio Classification (source: [youtube.com](https://youtu.be/KWwzcmG98Ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpAvPkQONBCC"
      },
      "source": [
        "Audio Classification can be used for an array of applications such as detecting a speaker's intent, classifying languages, or identifying animal species by their sounds. In our story, we aim to classify the speaker's intent from the audio input. Utilizing the pre-trained [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) model, we fine-tune it on the [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset specifically designed for this task. This method cuts down our training time and improves the model's performance even with less data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6-OvAnVNBCC"
      },
      "source": [
        "**Load MInDS-14 dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atbu5MSvNBCC"
      },
      "source": [
        "Start by loading the MInDS-14 dataset from the Datasets library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipnhaXYGNBCD"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUJjp63NBCD"
      },
      "source": [
        "Split the datasetâ€™s `train` split into a smaller train and test set with the [train_test_split](https://huggingface.co/docs/datasets/v2.13.1/en/package_reference/main_classes#datasets.Dataset.train_test_split) method. Thisâ€™ll give you a chance to experiment and make sure everything works before spending more time on the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJGq_dGJNBCD"
      },
      "outputs": [],
      "source": [
        "minds = minds.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBR4Gz7pNBCE"
      },
      "source": [
        "Then take a look at the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odwma1eNNBCE"
      },
      "outputs": [],
      "source": [
        "minds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYNKkLUANBCF"
      },
      "source": [
        "While the dataset contains a lot of useful information, like lang_id and english_transcription, youâ€™ll focus on the audio and intent_class in this guide. Remove the other columns with the [remove_columns](https://huggingface.co/docs/datasets/v2.13.1/en/package_reference/main_classes#datasets.Dataset.remove_columns) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaBuk195NBCF"
      },
      "outputs": [],
      "source": [
        "minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZe96TLiNBCH"
      },
      "source": [
        "Take a look at an example now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu4PdfMJNBCI"
      },
      "outputs": [],
      "source": [
        "minds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuz0YWAkNBCI"
      },
      "source": [
        "There are two fields:\n",
        "\n",
        "- audio: a 1-dimensional array of the speech signal that must be called to load and resample the audio file.\n",
        "- intent_class: represents the class id of the speakerâ€™s intent.\n",
        "\n",
        "To make it easier for the model to get the label name from the label id, create a dictionary that maps the label name to an integer and vice versa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8RvbRr6NBCJ"
      },
      "outputs": [],
      "source": [
        "labels = minds[\"train\"].features[\"intent_class\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qrFmU7HNBCJ"
      },
      "source": [
        "Now you can convert the label id to a label name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3hTZi0aNBCJ"
      },
      "outputs": [],
      "source": [
        "id2label[str(2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy3eFVQLNBCJ"
      },
      "source": [
        "**Preprocess**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5WWFdoUNBCK"
      },
      "source": [
        "The next step is to load a Wav2Vec2 feature extractor to process the audio signal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45z58kL2NBCK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz3lZLZKNBCK"
      },
      "source": [
        "The MInDS-14 dataset has a sampling rate of 8000khz (you can find this information in itâ€™s [dataset card](https://huggingface.co/datasets/PolyAI/minds14)), which means youâ€™ll need to resample the dataset to 16000kHz to use the pretrained Wav2Vec2 model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwcKexGvNBCK"
      },
      "outputs": [],
      "source": [
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "minds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFcdXga5NBCK"
      },
      "source": [
        "Create a preprocessing function to:\n",
        "\n",
        "1. Load and resample the audio file as required.\n",
        "2. Verify if the audio file's sampling rate matches that of the model's pre-training data (as seen in the Wav2Vec2 [model card](https://huggingface.co/facebook/wav2vec2-base)).\n",
        "3. Establish a maximum input length for batching longer inputs without truncation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU9Li72QNBCL"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
        "    )\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6XAw928NBCL"
      },
      "source": [
        "Use the Datasets map function to apply the preprocessing function across the complete dataset. Speed it up by enabling `batched=True` to process multiple dataset elements simultaneously. Remove unnecessary columns and rename `intent_class` to `label`, as the model expects this name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_BhgZZ5NBCL"
      },
      "outputs": [],
      "source": [
        "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
        "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Nbz_VaNBCL"
      },
      "source": [
        "**Setting up Evaluation Metric**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpaIWzCrNBCM"
      },
      "source": [
        "Incorporating a metric during training aids in gauging your model's performance. Use the Evaluate library to easily access an evaluation method. For this task, employ the accuracy metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV8tE5l3NBCM"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg_4hEEfNBCM"
      },
      "source": [
        "Then create a function that passes your predictions and labels to compute to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTiZtDigNBCM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vng-rQHvNBCM"
      },
      "source": [
        "Your `compute_metrics` function is ready to go now, and youâ€™ll return to it when you setup your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5FNrMRKNBCN"
      },
      "source": [
        "**Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N69G9IgINBCN"
      },
      "source": [
        "Youâ€™re ready to start training your model now! Load Wav2Vec2 with [AutoModelForAudioClassification](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/auto#transformers.AutoModelForAudioClassification) along with the number of expected labels, and the label mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKAFkWSENBCN"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForAudioClassification\n",
        "\n",
        "num_labels = len(id2label)\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP7NLiPINBCN"
      },
      "source": [
        "During the training phase, we have already implemented an optimization strategy. Here, we have set a learning rate and batch size in TrainingArguments. Additionally, the `load_best_model_at_end=True` option is set, implying that the Trainer will load the best model at the end of training, which is a form of model optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltLCQz3ENBCN"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"model/audio_classification\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,                  # learning rate\n",
        "    per_device_train_batch_size=32,      # training batch size\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,         # model optimization via early stopping\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_minds[\"train\"],\n",
        "    eval_dataset=encoded_minds[\"test\"],\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl7_xsskNBCO"
      },
      "source": [
        "**Evaluating the Trained Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W59J400UNBCO"
      },
      "source": [
        "After the training is completed, we need to evaluate the model. For that, we'll use the accuracy metric from the `evaluate` library to assess the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYVp4kISNBCQ"
      },
      "outputs": [],
      "source": [
        "eval_result = trainer.evaluate(eval_dataset=encoded_minds[\"test\"])\n",
        "print(eval_result) # print the evaluation results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmx11tvJNBCQ"
      },
      "source": [
        "The evaluation results will give us the accuracy on the test set. If this accuracy is satisfactory, we could then decide to publish the model. If it's not, we might need to revisit the preprocessing, model architecture, or the training process (e.g., tuning hyperparameters, increasing number of epochs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BUDt81oNBCR"
      },
      "source": [
        "Once training is completed, share your model to the Hub with the push_to_hub() method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of6ptzhPNBCR"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL8mV173NBCR"
      },
      "source": [
        "The following is an example of a model that has been trained: <https://huggingface.co/aditira/audio_classification>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDjRUTjUNBCR"
      },
      "source": [
        "**Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6w3olYqNBCR"
      },
      "source": [
        "Great, now that youâ€™ve finetuned a model, you can use it for inference!\n",
        "\n",
        "Load an audio file youâ€™d like to run inference on. Remember to resample the sampling rate of the audio file to match the sampling rate of the model if you need to!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BrSp_F2NBCR"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
        "audio_file = dataset[0][\"audio\"][\"path\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SstPWqUWNBCS"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a pipeline(). Instantiate a pipeline for audio classification with your model, and pass your audio file to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtFnQek_NBCS"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"audio-classification\", model=\"model/audio_classification\")\n",
        "classifier(audio_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy47-qvCNBCS"
      },
      "source": [
        "### Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k6vQiBqNBCS"
      },
      "source": [
        "[![](https://storage.googleapis.com/rg-ai-bootcamp/model_usage/image-classification.png)](https://youtu.be/tjAIM7BOYhw)\n",
        "\n",
        "Tasks: Image Classification (source: [youtube.com](https://youtu.be/tjAIM7BOYhw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ-cd3oCNBCT"
      },
      "source": [
        "Image classification can be used in countless applications, ranging from detecting objects in an image, satellite image analysis to medical imaging. In our case, we aim to classify food items from given images. By using a pre-trained [ViT](https://huggingface.co/docs/transformers/v4.31.0/en/tasks/model_doc/vit) model, fine-tuned on the [Food-101](https://huggingface.co/datasets/food101) dataset, we reduce the training time while preserving high performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYislCP0NBCT"
      },
      "source": [
        "**Load Food-101 dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Ch6s8NNBCT"
      },
      "source": [
        "Begin by loading a small subset of the Food-101 dataset from the Datasets library, allowing you to experiment and ensure everything works before committing to training on the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsrpv3y0NBCT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "food = load_dataset(\"food101\", split=\"train[:5000]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsOQZoJFNBCT"
      },
      "source": [
        "Split the datasetâ€™s train split into a train and test set with the `train_test_split` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfotga_dNBCU"
      },
      "outputs": [],
      "source": [
        "food = food.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oveDGhnSNBCU"
      },
      "source": [
        "Then take a look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMpoPbtJNBCU"
      },
      "outputs": [],
      "source": [
        "food[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m78gRW9pNBCV"
      },
      "source": [
        "Each example in the dataset has two fields:\n",
        "\n",
        "- `image`: a PIL image of the food item\n",
        "- `label`: the label class of the food item\n",
        "\n",
        "To make it easier for the model to get the label name from the label id, create a dictionary that maps the label name to an integer and vice versa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMfyX8mmNBCV"
      },
      "outputs": [],
      "source": [
        "labels = food[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaJjwlaONBCW"
      },
      "source": [
        "Now you can convert the label id to a label name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PXyFrQqNBCW"
      },
      "outputs": [],
      "source": [
        "id2label[str(79)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4VmpMNJNBCW"
      },
      "source": [
        "**Preprocess**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLNcjMg-NBCW"
      },
      "source": [
        "The next step is to load a ViT image processor to process the image into a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dnOMFYBNBCX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ELKreD1NBCX"
      },
      "source": [
        "Apply some image transformations to the images to make the model more robust against overfitting. Here youâ€™ll use torchvisionâ€™s transforms module, but you can also use any image library you like.\n",
        "\n",
        "Crop a random part of the image, resize it, and normalize it with the image mean and standard deviation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29My9xRKNBCX"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HK-7MrINBCX"
      },
      "source": [
        "Then create a preprocessing function to apply the transforms and return the pixel_values - the inputs to the model - of the image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWCD_moqNBCX"
      },
      "outputs": [],
      "source": [
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjR7xzQVNBCY"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use Datasets with_transform method. The transforms are applied on the fly when you load an element of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW3lIuheNBCY"
      },
      "outputs": [],
      "source": [
        "food = food.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYZE7JkTNBCY"
      },
      "source": [
        "Now create a batch of examples using DefaultDataCollator. Unlike other data collators in Transformers, the DefaultDataCollator does not apply additional preprocessing such as padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4EZgfaMNBCY"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sBg5WmFNBCY"
      },
      "source": [
        "**Setting up Evaluation Metric**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU0EINW6NBCY"
      },
      "source": [
        "Including a metric during training is often helpful for evaluating your modelâ€™s performance. You can quickly load an evaluation method with the Evaluate library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZT-SFL-NBCZ"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHuHm7QwNBCZ"
      },
      "source": [
        "Then create a function that passes your predictions and labels to compute to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qMDZNfRNBCZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZuxxP_UNBCZ"
      },
      "source": [
        "Your compute_metrics function is ready to go now, and youâ€™ll return to it when you set up your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgaPH-igNBCZ"
      },
      "source": [
        "**Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFBZkgWqNBCa"
      },
      "source": [
        "Youâ€™re ready to start training your model now! Load ViT with `AutoModelForImageClassification`. Specify the number of labels along with the number of expected labels, and the label mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwdFdf6-NBCa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXgzdhA7NBCa"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "- Set your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/trainer#transformers.TrainingArguments). Ensure `remove_unused_columns=False` to keep the image column, crucial for creating `pixel_values`. Specify `output_dir` to save your model and enable `push_to_hub` to upload it to Hugging Face. Trainer will conduct an accuracy evaluation and save a checkpoint after each epoch.\n",
        "- Feed these arguments, the model, dataset, tokenizer, data collator, and `compute_metrics` function to Trainer.\n",
        "- Use `train()` to fine-tune your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpQ2EHIkNBCa"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"model/image_classification\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,                 # learning rate\n",
        "    per_device_train_batch_size=16,     # training batch size\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,        # model optimization via early stopping\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=food[\"train\"],\n",
        "    eval_dataset=food[\"test\"],\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eZrghC_NBCb"
      },
      "source": [
        "**Evaluating the Trained Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWliiXFtNBCb"
      },
      "source": [
        "After the training is completed, we need to evaluate the model. For that, we'll use the accuracy metric from the `evaluate` library to assess the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qIY2l0qNBCb"
      },
      "outputs": [],
      "source": [
        "eval_result = trainer.evaluate(eval_dataset=food[\"test\"])\n",
        "print(eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwhT0Wz6NBCb"
      },
      "source": [
        "The evaluation results will give us the accuracy on the test set. If this accuracy is satisfactory, we could then decide to publish the model. If it's not, we might need to revisit the preprocessing, model architecture, or the training process (e.g., tuning hyperparameters, increasing number of epochs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGXP8gtVNBCb"
      },
      "source": [
        "Once training is completed, share your model to the Hub with the `push_to_hub()` method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O6XPJqmNBCb"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9KqI9sENBCc"
      },
      "source": [
        "The following is an example of a model that has been trained: <https://huggingface.co/aditira/image_classification>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP3nzS2hNBCc"
      },
      "source": [
        "**Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVb-zZHFNBCc"
      },
      "source": [
        "Great, now that youâ€™ve fine-tuned a model, you can use it for inference!\n",
        "\n",
        "Load an image youâ€™d like to run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjkZr6yBNBCc"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"food101\", split=\"validation[:10]\")\n",
        "image = ds[\"image\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUeV0C4JNBCd"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a pipeline(). Instantiate a pipeline for image classification with your model, and pass your image to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaZ8_-4DNBCd"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"image-classification\", model=\"my_awesome_food_model\")\n",
        "classifier(image)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}